{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/s/ls4/users/grartem/RL_robots/CommandClassifier\")\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "\n",
    "torch.cuda.is_available()\n",
    "import yaml\n",
    "import pyhocon\n",
    "import joblib\n",
    "from copy import deepcopy\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import simpletransformers\n",
    "from sklearn.metrics import classification_report\n",
    "from RobotCommandClassifier import utils\n",
    "from RobotCommandClassifier import *\n",
    "from MultilabelML import PrepareData, PrepareInput_for_simpletransformers, PrepareModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configFileContent = pyhocon.ConfigFactory.parse_file(\"../Configs/SimpleLM.conf\")\n",
    "#CONFIG = configFileContent['rubert_tiny2_multilabel_noYno0_fold4'].as_plain_ordered_dict()\n",
    "#configFileContent = pyhocon.ConfigFactory.parse_file(\"../Configs/CustomML.conf\")\n",
    "#CONFIG = configFileContent['MyMultiTiny2_data2_fold0'].as_plain_ordered_dict()\n",
    "with open(\"/s/ls4/users/grartem/RL_robots/CommandClassifier/models/MyMultiMLangBert_data3v2/fold_2/config.json\", \"r\") as f:\n",
    "    CONFIG = json.load(f)\n",
    "\n",
    "# если хотим протестировать на всем тесте, включая фолды, на которых он обучался\n",
    "#CONFIG[\"Data\"].pop(\"test_only_on_fold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_df, train_y_df, valid_x_df, valid_y_df, test_x_df, test_y_df = PrepareData(CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['checkpoint-10964-epoch-2',\n",
       " 'checkpoint-16446-epoch-3',\n",
       " 'checkpoint-21928-epoch-4',\n",
       " 'checkpoint-5482-epoch-1']"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([x for x in os.listdir(CONFIG[\"output_dir\"] + '/models/') if \"epoch\" in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "We couldn't connect to 'https://huggingface.co' to load this model, couldn't find it in the cached files and it looks like /s/ls4/users/grartem/RL_robots/CommandClassifier/models/MyMultiMLangBert_data3/fold_4/models/checkpoint-54820-epoch-10 is not the path to a directory containing a {configuration_file} file.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/simptr/lib/python3.8/site-packages/transformers/configuration_utils.py:596\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 596\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError:\n",
      "File \u001b[0;32m~/anaconda3/envs/simptr/lib/python3.8/site-packages/transformers/utils/hub.py:282\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_remote_url(url_or_filename):\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;66;03m# URL, so get it from the cache (downloading if necessary)\u001b[39;00m\n\u001b[0;32m--> 282\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m \u001b[43mget_from_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_or_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(url_or_filename):\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;66;03m# File, and it exists.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/simptr/lib/python3.8/site-packages/transformers/utils/hub.py:545\u001b[0m, in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 545\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    546\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection error, and we cannot find the requested files in the cached path.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    547\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please try again or make sure your Internet connection is on.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    548\u001b[0m                 )\n\u001b[1;32m    550\u001b[0m \u001b[38;5;66;03m# From now on, etag is not None.\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Connection error, and we cannot find the requested files in the cached path. Please try again or make sure your Internet connection is on.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[0;32mIn [178]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m epoch_to_checkpoint \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m5482\u001b[39m,\u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m10964\u001b[39m,\u001b[38;5;241m3\u001b[39m:\u001b[38;5;241m16446\u001b[39m,\u001b[38;5;241m4\u001b[39m:\u001b[38;5;241m21928\u001b[39m,\u001b[38;5;241m5\u001b[39m:\u001b[38;5;241m27410\u001b[39m,\u001b[38;5;241m6\u001b[39m:\u001b[38;5;241m32892\u001b[39m,\u001b[38;5;241m7\u001b[39m:\u001b[38;5;241m38374\u001b[39m,\u001b[38;5;241m8\u001b[39m:\u001b[38;5;241m43856\u001b[39m,\u001b[38;5;241m9\u001b[39m:\u001b[38;5;241m49338\u001b[39m,\u001b[38;5;241m10\u001b[39m:\u001b[38;5;241m54820\u001b[39m,\n\u001b[1;32m     11\u001b[0m                       \u001b[38;5;241m11\u001b[39m:\u001b[38;5;241m60302\u001b[39m, \u001b[38;5;241m12\u001b[39m:\u001b[38;5;241m65784\u001b[39m, \u001b[38;5;241m13\u001b[39m:\u001b[38;5;241m71266\u001b[39m, \u001b[38;5;241m14\u001b[39m:\u001b[38;5;241m76748\u001b[39m, \u001b[38;5;241m15\u001b[39m:\u001b[38;5;241m82230\u001b[39m, \u001b[38;5;241m16\u001b[39m:\u001b[38;5;241m87712\u001b[39m, \u001b[38;5;241m17\u001b[39m:\u001b[38;5;241m93194\u001b[39m, \u001b[38;5;241m18\u001b[39m:\u001b[38;5;241m98676\u001b[39m, \u001b[38;5;241m19\u001b[39m:\u001b[38;5;241m104158\u001b[39m, \u001b[38;5;241m20\u001b[39m:\u001b[38;5;241m109640\u001b[39m}\n\u001b[1;32m     12\u001b[0m CONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m CONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/models/checkpoint-\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m-epoch-\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch_to_checkpoint[epoch_i], epoch_i)\n\u001b[0;32m---> 14\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mPrepareModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/RL_robots/CommandClassifier/MultilabelML.py:82\u001b[0m, in \u001b[0;36mPrepareModel\u001b[0;34m(CONFIG)\u001b[0m\n\u001b[1;32m     80\u001b[0m     model_args \u001b[38;5;241m=\u001b[39m MyMultiLabelClassificationArgs(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mCONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# Create a MultiLabelClassificationModel\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mMyMultiLabelClassificationModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mModel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mModel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mModel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_labels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cuda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_sublabels_per_biglabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mModel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnum_sublabels_per_biglabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_attention_for_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mModel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madd_attention_for_labels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown Type of experiment:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(CONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mType\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n",
      "File \u001b[0;32m~/RL_robots/CommandClassifier/RobotCommandClassifier/MyMultilabel.py:258\u001b[0m, in \u001b[0;36mMyMultiLabelClassificationModel.__init__\u001b[0;34m(self, model_type, model_name, num_labels, pos_weight, args, use_cuda, cuda_device, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m config_class, model_class, tokenizer_class \u001b[38;5;241m=\u001b[39m MODEL_CLASSES[model_type]\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_labels:\n\u001b[0;32m--> 258\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m \u001b[43mconfig_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_labels \u001b[38;5;241m=\u001b[39m num_labels\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/simptr/lib/python3.8/site-packages/transformers/configuration_utils.py:521\u001b[0m, in \u001b[0;36mPretrainedConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_pretrained\u001b[39m(\u001b[38;5;28mcls\u001b[39m, pretrained_model_name_or_path: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPretrainedConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    Instantiate a [`PretrainedConfig`] (or a derived class) from a pretrained model configuration.\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;124;03m    assert unused_kwargs == {\"foo\": False}\u001b[39;00m\n\u001b[1;32m    520\u001b[0m \u001b[38;5;124;03m    ```\"\"\"\u001b[39;00m\n\u001b[0;32m--> 521\u001b[0m     config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type:\n\u001b[1;32m    523\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    524\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are using a model of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to instantiate a model of type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    525\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is not supported for all configurations of models and can yield errors.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    526\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/simptr/lib/python3.8/site-packages/transformers/configuration_utils.py:548\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    547\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 548\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;66;03m# That config file may point us toward another config file to use.\u001b[39;00m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfiguration_files\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n",
      "File \u001b[0;32m~/anaconda3/envs/simptr/lib/python3.8/site-packages/transformers/configuration_utils.py:629\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    626\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere was a specific connection error when trying to load \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    627\u001b[0m     )\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m--> 629\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    630\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe couldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt connect to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHUGGINGFACE_CO_RESOLVE_ENDPOINT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to load this model, couldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find it in the cached \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiles and it looks like \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not the path to a directory containing a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{configuration_file}\u001b[39;00m\u001b[38;5;124m file.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCheckout your internet connection or see how to run the library in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moffline mode at \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/docs/transformers/installation#offline-mode\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    634\u001b[0m     )\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[1;32m    636\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load config for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. If you were trying to load it from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, make sure you don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have a local directory with the same name. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    639\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOtherwise, make sure \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is the correct path to a directory \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    640\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontaining a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfiguration_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m file\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    641\u001b[0m     )\n",
      "\u001b[0;31mOSError\u001b[0m: We couldn't connect to 'https://huggingface.co' to load this model, couldn't find it in the cached files and it looks like /s/ls4/users/grartem/RL_robots/CommandClassifier/models/MyMultiMLangBert_data3/fold_4/models/checkpoint-54820-epoch-10 is not the path to a directory containing a {configuration_file} file.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'."
     ]
    }
   ],
   "source": [
    "epoch_i = 10\n",
    "# MyMultiTiny2\n",
    "epoch_to_checkpoint = {1:2058,2:4116,3:6174,4:8232,5:10290,6:12348,7:14406,8:16464,9:18522,10:20580}\n",
    "# MyMultiTiny2_data2\n",
    "epoch_to_checkpoint = {1:6378,2:12756,3:19134,4:25512,5:31890,6:38268,7:44646,8:51024,9:57402,10:63780}\n",
    "#MyMultiTiny2_data3\n",
    "epoch_to_checkpoint = {1:5481,2:10962,3:16443,4:21924,5:27405,6:32886,7:38367,8:43848,9:49329,10:54810,\n",
    "                      11:60291, 12:65772, 13:71253, 14:76734, 15:82215, 16:87696, 17:93177, 18:98658, 19:104139, 20:109620}\n",
    "#MyMultiTiny2_data3 fold 3, 4\n",
    "epoch_to_checkpoint = {1:5482,2:10964,3:16446,4:21928,5:27410,6:32892,7:38374,8:43856,9:49338,10:54820,\n",
    "                      11:60302, 12:65784, 13:71266, 14:76748, 15:82230, 16:87712, 17:93194, 18:98676, 19:104158, 20:109640}\n",
    "CONFIG[\"Model\"]['model_name'] = CONFIG[\"output_dir\"] + '/models/checkpoint-{}-epoch-{}'.format(epoch_to_checkpoint[epoch_i], epoch_i)\n",
    "\n",
    "model = PrepareModel(CONFIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, raw_outputs = model.predict(test_x_df.values.tolist())\n",
    "#predictions = np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#привести бинарный мультилейбл к мультиклассовому\n",
    "classes_per_attribute = CONFIG[\"Model\"]['num_sublabels_per_biglabel']\n",
    "predictions_2 = utils.binarymultilabel_to_multiclassmultilabel(raw_outputs, classes_per_attribute, CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(CONFIG[\"output_dir\"], \"reports\")):\n",
    "    os.mkdir(os.path.join(CONFIG[\"output_dir\"], \"reports\"))\n",
    "#result = utils.calculate_metrics_2(test_y_df.iloc[:,1:], predictions_2[:,1:], display=True) # исключить Y из оценки\n",
    "result = utils.calculate_metrics_2(test_y_df, predictions_2, display=True)\n",
    "with open(os.path.join(CONFIG[\"output_dir\"], \"reports/epoch-{}_classes_report.json\".format(epoch_i)), \"w\") as f:\n",
    "    json.dump(result, f)\n",
    "\n",
    "#result_avg = utils.calculate_metrics(test_y_df.iloc[:,1:], predictions_2[:,1:], config={\n",
    "result_avg = utils.calculate_metrics(test_y_df, predictions_2, config={\n",
    "    \"report_metrics\": CONFIG[\"Report\"][\"report_metrics\"]\n",
    "})\n",
    "with open(os.path.join(CONFIG[\"output_dir\"], \"reports/epoch-{}_avg_report.json\".format(epoch_i)), \"w\") as f:\n",
    "    json.dump(result_avg, f)\n",
    "for k, v in result_avg.items():\n",
    "    print(np.round(v*100), \"\\t\", k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_combinations = pd.read_csv(\"../Data/Interim/possible_combinations_of_attributes_for_actions.csv\")\n",
    "possible_combinations_arr = possible_combinations.loc[:, CONFIG[\"Data\"][\"target_columns\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule\n",
    "def softmax(x):\n",
    "    #e_x = x - np.expand_dims(np.max(x, axis=1), axis=1)\n",
    "    #return e_x / np.expand_dims(e_x.sum(axis=1), axis=1)\n",
    "    e_x = np.exp(x)\n",
    "    return e_x / np.expand_dims(np.sum(e_x, axis=1), axis=1)\n",
    "softmax_outputs = np.zeros_like(raw_outputs, dtype=np.float32)\n",
    "shift = 0\n",
    "for num_sublabels in CONFIG['Model']['num_sublabels_per_biglabel']:\n",
    "    softmax_outputs[:, shift:shift + num_sublabels] = softmax(raw_outputs[:, shift:shift + num_sublabels])\n",
    "    shift += num_sublabels\n",
    "\n",
    "predictions_3 = []\n",
    "for i in range(len(softmax_outputs)):\n",
    "    shift = 0\n",
    "    probs_for_combinations = np.zeros_like(possible_combinations_arr, dtype=np.float32)\n",
    "    # предполагается, что первые значения в выходном векторе из модели - классы экшена\n",
    "    assert CONFIG[\"Data\"][\"target_columns\"][0]==\"action\"\n",
    "    probs_for_combinations[:,0] = np.take(softmax_outputs[i, shift:shift+classes_per_attribute[0]], possible_combinations_arr[:,0])\n",
    "    shift += classes_per_attribute[0]\n",
    "    #print(probs_for_combinations[:,0])\n",
    "    maxprob_attribute_classes = [-1] # -1 for action\n",
    "    for attribute_i in range(1, len(classes_per_attribute)):\n",
    "        # есть вариант ставить 0 для нулевых классов или наоборот - обратное от максимального класса\n",
    "        probs = softmax_outputs[i, shift:shift+classes_per_attribute[attribute_i]]\n",
    "        assert np.round(sum(probs), 5)==1\n",
    "        zerocls_prob = probs[0]\n",
    "        nonzerocls_max_prob = np.max(probs[1:])\n",
    "        #print(zerocls_prob, nonzerocls_max_prob)\n",
    "        maxprob_attribute_classes.append(np.argmax(probs[1:])+1)\n",
    "        probs_for_combinations[possible_combinations_arr[:, attribute_i]==0, attribute_i] = zerocls_prob\n",
    "        probs_for_combinations[possible_combinations_arr[:, attribute_i]==1, attribute_i] = nonzerocls_max_prob\n",
    "        shift += classes_per_attribute[attribute_i]\n",
    "\n",
    "    best_template_i = np.argmax(np.sum(probs_for_combinations, axis=1))\n",
    "    sample_prediction = possible_combinations_arr[best_template_i].copy()\n",
    "    for i in range(1, len(classes_per_attribute)):\n",
    "        if sample_prediction[i]!=0:\n",
    "            sample_prediction[i]=maxprob_attribute_classes[i]\n",
    "    predictions_3.append(sample_prediction)\n",
    "predictions_3 = np.array(predictions_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(CONFIG[\"output_dir\"], \"reports\")):\n",
    "    os.mkdir(os.path.join(CONFIG[\"output_dir\"], \"reports\"))\n",
    "result = utils.calculate_metrics_2(test_y_df, predictions_3, display=True)\n",
    "with open(os.path.join(CONFIG[\"output_dir\"], \"reports/epoch-{}_classes_report_rule.json\".format(epoch_i)), \"w\") as f:\n",
    "    json.dump(result, f)\n",
    "\n",
    "result_avg = utils.calculate_metrics(test_y_df, predictions_3, config={\n",
    "    \"report_metrics\": CONFIG[\"Report\"][\"report_metrics\"]\n",
    "})\n",
    "with open(os.path.join(CONFIG[\"output_dir\"], \"reports/epoch-{}_avg_report_rule.json\".format(epoch_i)), \"w\") as f:\n",
    "    json.dump(result_avg, f)\n",
    "for k, v in result_avg.items():\n",
    "    print(np.round(v*100), \"\\t\", k)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Сохранить ошибки\n",
    "with open(\"../Data/Interim/labels_names.json\", \"r\") as f:\n",
    "    labels_names = json.load(f)\n",
    "predict_df = pd.DataFrame(predictions_2.astype(np.int))\n",
    "predict_df.columns = [c+\"_pred\" for c in test_y_df.columns]\n",
    "predict_df.index = test_y_df.index\n",
    "errors = pd.concat([test_x_df, test_y_df, predict_df], axis=1)\n",
    "for c in errors.columns:\n",
    "    if c in \"x\":\n",
    "        continue\n",
    "    if \"_pred\" in c:\n",
    "        errors[c] = errors[c].map(lambda x: labels_names[c.replace(\"_pred\", \"\")][x])\n",
    "    else:\n",
    "        errors[c] = errors[c].map(lambda x: labels_names[c][x])\n",
    "errors = errors.loc[:, [\"x\"] + [x for c in test_y_df.columns if c!= \"x\" for x in [c,c+\"_pred\"]]]\n",
    "\n",
    "fullDF = pd.read_csv(CONFIG[\"Data\"][\"path_to_df\"])\n",
    "fullDF = fullDF[fullDF[\"subset\"]==\"test\"]\n",
    "errors = pd.concat([errors, fullDF.loc[fullDF.index.isin(errors.index),[\"type\", \"fold\"]]], axis=1)\n",
    "\n",
    "isCorrectColumn = None\n",
    "for c in test_y_df.columns:\n",
    "    if isCorrectColumn is None:\n",
    "        isCorrectColumn = errors[c]==errors[c+\"_pred\"]\n",
    "    else:\n",
    "        isCorrectColumn &= errors[c]==errors[c+\"_pred\"]\n",
    "errors[\"корректность\"] = isCorrectColumn.map(lambda x: '' if x else \"ошибка\")\n",
    "\n",
    "errors.to_csv(\"../Docs/myMultiTiny2_errors_fold4_test.csv\", sep=\";\", encoding=\"cp1251\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simptr",
   "language": "python",
   "name": "simptr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
