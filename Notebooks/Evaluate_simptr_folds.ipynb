{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/s/ls4/users/grartem/RL_robots/CommandClassifier\")\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "\n",
    "torch.cuda.is_available()\n",
    "import yaml\n",
    "import pyhocon\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import simpletransformers\n",
    "from sklearn.metrics import classification_report\n",
    "from simpletransformers.classification import (\n",
    "    MultiLabelClassificationModel, MultiLabelClassificationArgs,\n",
    "    ClassificationModel, ClassificationArgs\n",
    ")\n",
    "from RobotCommandClassifier.MyMultilabel import MyMultiLabelClassificationModel, MyMultiLabelClassificationArgs\n",
    "from RobotCommandClassifier import utils\n",
    "from RobotCommandClassifier import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "configFileContent = pyhocon.ConfigFactory.parse_file(\"../Configs/SimpleLM.conf\")\n",
    "CONFIG = configFileContent['rubert_tiny2_multilabel_noYno0_fold4'].as_plain_ordered_dict()\n",
    "#configFileContent = pyhocon.ConfigFactory.parse_file(\"../Configs/CustomML.conf\")\n",
    "#CONFIG = configFileContent['MyMultiTiny2_att_fold0'].as_plain_ordered_dict()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# если хотим протестировать на всем тесте, включая фолды, на которых он обучался\n",
    "CONFIG[\"Data\"].pop(\"test_only_on_fold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_df, train_y_df, valid_x_df, valid_y_df, test_x_df, test_y_df = utils.load_data(**CONFIG[\"Data\"])\n",
    "\n",
    "if CONFIG[\"Data\"].get(\"add_y_to_x\", False):\n",
    "    with open(CONFIG[\"Data\"][\"y_descriptions_path\"], \"r\") as f:\n",
    "        y_descriptioons = json.load(f)\n",
    "    train_x_df = train_x_df[\"y\"].map(lambda y: y_descriptioons[int(y)]) + \": \" + train_x_df[\"x\"]\n",
    "    valid_x_df = valid_x_df[\"y\"].map(lambda y: y_descriptioons[int(y)]) + \": \" + valid_x_df[\"x\"]\n",
    "    test_x_df = test_x_df[\"y\"].map(lambda y: y_descriptioons[int(y)]) + \": \" + test_x_df[\"x\"]\n",
    "\n",
    "if CONFIG[\"Data\"].get(\"predict_label_flag\", False):\n",
    "    if \"y\" in CONFIG[\"Data\"][\"target_columns\"]:\n",
    "        raise ValueError(\"Указан флаг для использования только бинарных лейблов. Предполагается, что в таком случае 'y' не должен ыть среди target_columns.\")\n",
    "    train_y_df[train_y_df!=0] = 1\n",
    "    valid_y_df[valid_y_df!=0] = 1\n",
    "    test_y_df[test_y_df!=0] = 1\n",
    "if CONFIG[\"Type\"] in [\"simple_ml_multilabel_classifier\", \"mymulti_classifier\"]:\n",
    "    if CONFIG[\"Data\"].get(\"predict_label_flag\", False):\n",
    "        labels = train_y_df.values.tolist()\n",
    "    else:\n",
    "        enc = OneHotEncoder(**CONFIG[\"Data\"].get(\"OneHotArgs\", {}))\n",
    "        enc.fit(train_y_df.values)\n",
    "\n",
    "        labels = []\n",
    "        encoded_labels = enc.transform(train_y_df.values).toarray().astype(int)\n",
    "        for i in range(train_y_df.shape[0]):\n",
    "            labels.append(encoded_labels[i].tolist())\n",
    "    train_df = pd.DataFrame(list(zip(train_x_df, labels)))        \n",
    "else:\n",
    "    train_df = pd.concat([train_x_df, train_y_df], axis=1)\n",
    "train_df.columns = [\"text\", \"labels\"]\n",
    "\n",
    "if CONFIG[\"Type\"] == \"simple_ml_classifier\":\n",
    "    num_labels = len(train_y_df.iloc[:,0].unique())\n",
    "else:\n",
    "    num_labels = len(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "CONFIG[\"Model\"][\"Args\"][\"output_dir\"] = CONFIG[\"output_dir\"]+\"/models/\"\n",
    "CONFIG[\"Model\"][\"Args\"][\"best_model_dir\"] = CONFIG[\"output_dir\"] + \"/models/best_model\"\n",
    "if CONFIG[\"Type\"] == \"simple_ml_multilabel_classifier\":\n",
    "    model_args = MultiLabelClassificationArgs(**CONFIG[\"Model\"][\"Args\"])\n",
    "    model = MultiLabelClassificationModel(\n",
    "        CONFIG[\"Model\"][\"model_type\"],\n",
    "        CONFIG[\"output_dir\"] + '/models/checkpoint-63780-epoch-10',\n",
    "        num_labels=num_labels,\n",
    "        use_cuda=True,    \n",
    "        args=model_args,\n",
    "    )\n",
    "elif CONFIG[\"Type\"] == \"simple_ml_classifier\":\n",
    "    model_args = ClassificationArgs(**CONFIG[\"Model\"][\"Args\"])\n",
    "    model = ClassificationModel(\n",
    "        CONFIG[\"Model\"][\"model_type\"],\n",
    "        CONFIG[\"output_dir\"] + '/models/checkpoint-63780-epoch-10',\n",
    "        num_labels=num_labels,\n",
    "        use_cuda=True,    \n",
    "        args=model_args,\n",
    "    )\n",
    "elif CONFIG[\"Type\"] == \"mymulti_classifier\":\n",
    "    model_args = MyMultiLabelClassificationArgs(**CONFIG[\"Model\"][\"Args\"])\n",
    "    # Create a MultiLabelClassificationModel\n",
    "    model = MyMultiLabelClassificationModel(\n",
    "        CONFIG[\"Model\"][\"model_type\"],\n",
    "        CONFIG[\"output_dir\"] + '/models/checkpoint-63780-epoch-10',\n",
    "        num_labels=num_labels,\n",
    "        use_cuda=True,\n",
    "        num_sublabels_per_biglabel = CONFIG[\"Model\"][\"num_sublabels_per_biglabel\"],\n",
    "        add_attention_for_labels=CONFIG[\"Model\"][\"add_attention_for_labels\"],\n",
    "        args=model_args,\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(\"unknown Type of experiment:{}\".format(CONFIG[\"Type\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c0d9c4cbed48cc8956088e4e1085b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/263 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "658cb45fd2ef4073bb34bf448b8f6215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions, raw_outputs = model.predict(test_x_df.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#привести бинарный мультилейбл к мультиклассовому\n",
    "with open(\"../Data/Interim/active_labels_for_y.json\", \"r\") as f:\n",
    "    active_labels_for_y = json.load(f)\n",
    "predictions_2 = np.zeros((len(predictions), len(enc.categories_)))\n",
    "for i in range(len(predictions)):\n",
    "    shift = 0\n",
    "    for j in range(len(enc.categories_)):\n",
    "        if \"OneHotArgs\" in CONFIG[\"Data\"] and CONFIG[\"Data\"][\"OneHotArgs\"].get('drop', None) == \"first\":\n",
    "            label_logits = raw_outputs[i, shift:shift+len(enc.categories_[j])-1]\n",
    "            if sum(label_logits>=0.5)==0:\n",
    "                predictions_2[i,j] = 0\n",
    "            else:\n",
    "                predictions_2[i,j] = np.argmax(label_logits)+1\n",
    "            shift += len(enc.categories_[j])-1\n",
    "        else:\n",
    "            predictions_2[i,j] = np.argmax(raw_outputs[i, shift:shift+len(enc.categories_[j])])\n",
    "            shift += len(enc.categories_[j])\n",
    "    assert shift==len(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.44      0.70      0.54        10\n",
      "         2.0       0.40      0.50      0.44         8\n",
      "         3.0       0.00      0.00      0.00        10\n",
      "         6.0       0.99      0.99      0.99       235\n",
      "         7.0       0.00      0.00      0.00         0\n",
      "         9.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.93       263\n",
      "   macro avg       0.30      0.37      0.33       263\n",
      "weighted avg       0.91      0.93      0.92       263\n",
      "\n",
      "direction\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99       245\n",
      "         1.0       1.00      0.20      0.33         5\n",
      "         2.0       0.00      0.00      0.00         3\n",
      "         3.0       0.00      0.00      0.00         0\n",
      "         4.0       1.00      0.80      0.89        10\n",
      "         7.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.97       263\n",
      "   macro avg       0.50      0.33      0.37       263\n",
      "weighted avg       0.97      0.97      0.96       263\n",
      "\n",
      "meters\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       263\n",
      "\n",
      "    accuracy                           1.00       263\n",
      "   macro avg       1.00      1.00      1.00       263\n",
      "weighted avg       1.00      1.00      1.00       263\n",
      "\n",
      "degshours\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       263\n",
      "\n",
      "    accuracy                           1.00       263\n",
      "   macro avg       1.00      1.00      1.00       263\n",
      "weighted avg       1.00      1.00      1.00       263\n",
      "\n",
      "object1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.96      0.95        28\n",
      "         1.0       0.86      1.00      0.92        55\n",
      "         2.0       0.84      1.00      0.91        26\n",
      "         3.0       1.00      0.86      0.92        21\n",
      "         4.0       0.95      0.68      0.79        31\n",
      "         5.0       0.98      0.91      0.94        53\n",
      "         6.0       0.98      0.98      0.98        49\n",
      "         8.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.92       263\n",
      "   macro avg       0.82      0.80      0.80       263\n",
      "weighted avg       0.93      0.92      0.92       263\n",
      "\n",
      "nearest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00       263\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.99       263\n",
      "   macro avg       0.50      0.50      0.50       263\n",
      "weighted avg       1.00      0.99      1.00       263\n",
      "\n",
      "relation1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96        38\n",
      "           1       0.96      0.94      0.95        96\n",
      "           2       0.95      0.96      0.96       129\n",
      "\n",
      "    accuracy                           0.95       263\n",
      "   macro avg       0.95      0.96      0.96       263\n",
      "weighted avg       0.95      0.95      0.95       263\n",
      "\n",
      "object2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        38\n",
      "           1       0.98      0.84      0.91        75\n",
      "           2       0.97      1.00      0.99        35\n",
      "           3       0.64      0.90      0.75        10\n",
      "           4       0.83      0.87      0.85        46\n",
      "           5       0.78      1.00      0.88        14\n",
      "           6       0.91      0.91      0.91        45\n",
      "\n",
      "    accuracy                           0.91       263\n",
      "   macro avg       0.87      0.93      0.89       263\n",
      "weighted avg       0.92      0.91      0.91       263\n",
      "\n",
      "relation2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94        64\n",
      "           1       0.96      0.93      0.94       123\n",
      "           2       0.99      0.93      0.96        76\n",
      "\n",
      "    accuracy                           0.95       263\n",
      "   macro avg       0.94      0.95      0.95       263\n",
      "weighted avg       0.95      0.95      0.95       263\n",
      "\n",
      "object3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87        64\n",
      "           1       0.94      0.92      0.93        49\n",
      "           2       1.00      0.82      0.90        17\n",
      "           3       1.00      0.64      0.78        25\n",
      "           4       0.87      0.82      0.85        40\n",
      "           5       0.86      1.00      0.92        12\n",
      "           6       0.98      0.88      0.92        56\n",
      "\n",
      "    accuracy                           0.89       263\n",
      "   macro avg       0.92      0.87      0.88       263\n",
      "weighted avg       0.90      0.89      0.89       263\n",
      "\n",
      "self\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       263\n",
      "\n",
      "    accuracy                           1.00       263\n",
      "   macro avg       1.00      1.00      1.00       263\n",
      "weighted avg       1.00      1.00      1.00       263\n",
      "\n",
      "gaze\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.98      0.99       263\n",
      "         1.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.98       263\n",
      "   macro avg       0.50      0.49      0.50       263\n",
      "weighted avg       1.00      0.98      0.99       263\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.0 \t correct_samples_perc\n",
      "93.0 \t [action]_acc\n",
      "33.0 \t [action]_macrof1\n",
      "97.0 \t [direction]_acc\n",
      "37.0 \t [direction]_macrof1\n",
      "100.0 \t [meters]_acc\n",
      "100.0 \t [meters]_macrof1\n",
      "100.0 \t [degshours]_acc\n",
      "100.0 \t [degshours]_macrof1\n",
      "92.0 \t [object1]_acc\n",
      "80.0 \t [object1]_macrof1\n",
      "99.0 \t [nearest]_acc\n",
      "50.0 \t [nearest]_macrof1\n",
      "95.0 \t [relation1]_acc\n",
      "96.0 \t [relation1]_macrof1\n",
      "91.0 \t [object2]_acc\n",
      "89.0 \t [object2]_macrof1\n",
      "95.0 \t [relation2]_acc\n",
      "95.0 \t [relation2]_macrof1\n",
      "89.0 \t [object3]_acc\n",
      "88.0 \t [object3]_macrof1\n",
      "100.0 \t [self]_acc\n",
      "100.0 \t [self]_macrof1\n",
      "98.0 \t [gaze]_acc\n",
      "50.0 \t [gaze]_macrof1\n",
      "76.0 \t avg_macro_f1\n",
      "96.0 \t avg_acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(os.path.join(CONFIG[\"output_dir\"], \"reports\")):\n",
    "    os.mkdir(os.path.join(CONFIG[\"output_dir\"], \"reports\"))\n",
    "#result = utils.calculate_metrics_2(test_y_df.iloc[:,1:], predictions_2[:,1:], display=True) # исключить Y из оценки\n",
    "result = utils.calculate_metrics_2(test_y_df, predictions_2, display=True)\n",
    "with open(os.path.join(CONFIG[\"output_dir\"], \"reports/epoch-10_classes_report.json\"), \"w\") as f:\n",
    "    json.dump(result, f)\n",
    "\n",
    "#result_avg = utils.calculate_metrics(test_y_df.iloc[:,1:], predictions_2[:,1:], config={\n",
    "result_avg = utils.calculate_metrics(test_y_df, predictions_2, config={\n",
    "    \"report_metrics\": CONFIG[\"Report\"][\"report_metrics\"]\n",
    "})\n",
    "with open(os.path.join(CONFIG[\"output_dir\"], \"reports/epoch-10_avg_report.json\"), \"w\") as f:\n",
    "    json.dump(result_avg, f)\n",
    "for k, v in result_avg.items():\n",
    "    print(np.round(v*100), \"\\t\", k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# выбрать только возможные или максимально правдоподобные\n",
    "possible_combinations = pd.read_csv(\"../Data/Interim/possible_combinations.csv\")\n",
    "possible_tuples = []\n",
    "for ir, row in possible_combinations.loc[:, CONFIG[\"Data\"][\"target_columns\"]].iterrows():\n",
    "    possible_tuples.append(tuple(row.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No possible tuples for 116\n",
      "[[[8, 6, 0, 0, 0, 8, 0, 2, 4, 1, 6, 0, 0], 11.85870361328125], [[8, 6, 0, 0, 0, 8, 0, 2, 4, 1, 4, 0, 0], 11.9217529296875], [[8, 6, 0, 0, 0, 8, 0, 2, 4, 1, 1, 0, 0], 12.33251953125]]\n"
     ]
    }
   ],
   "source": [
    "# Rule\n",
    "with open(\"../Data/Interim/active_labels_for_y.json\", \"r\") as f:\n",
    "    active_labels_for_y = json.load(f)\n",
    "predictions_3 = []\n",
    "for i in range(len(predictions)):\n",
    "    shift = 0\n",
    "    predicted_tuples = []\n",
    "    for cat_i in range(len(enc.categories_)):        \n",
    "        probs = raw_outputs[i, shift:shift+len(enc.categories_[cat_i])]\n",
    "        chosen_probs = np.where(probs>0.7)[0]\n",
    "        if len(chosen_probs)==0:\n",
    "            #chosen_probs = [np.argmax(probs)]\n",
    "            #print(\"Low confidence\", CONFIG[\"Data\"][\"target_columns\"][cat_i], np.round(probs, 3))\n",
    "            chosen_probs = np.argsort(probs)[-3:]\n",
    "        if cat_i==0:\n",
    "            for cls in chosen_probs:\n",
    "                predicted_tuples.append([[cls], probs[cls]])\n",
    "        else:\n",
    "            if len(chosen_probs)==1:\n",
    "                for tp in predicted_tuples:\n",
    "                    tp[0].append(chosen_probs[0])\n",
    "                    tp[1] += probs[chosen_probs[0]]\n",
    "            elif len(chosen_probs)>1:\n",
    "                #print(i, CONFIG[\"Data\"][\"target_columns\"][cat_i], \"more than 1 prob\", chosen_probs)\n",
    "                new_tuples = []\n",
    "                for tp in predicted_tuples:\n",
    "                    tp_template = deepcopy(tp)\n",
    "                    for cls_i, cls in enumerate(chosen_probs):\n",
    "                        if cls_i==0:\n",
    "                            tp[0].append(cls)\n",
    "                            tp[1] += probs[cls]\n",
    "                        else:\n",
    "                            new_tp = deepcopy(tp_template)\n",
    "                            new_tp[0].append(cls)\n",
    "                            new_tp[1] += probs[cls]\n",
    "                            new_tuples.append(new_tp)\n",
    "                predicted_tuples.extend(new_tuples)\n",
    "        shift += len(enc.categories_[cat_i])\n",
    "    possible_predicted_tuples = []\n",
    "    for tp in predicted_tuples:\n",
    "        assert len(tp[0])==len(CONFIG[\"Data\"][\"target_columns\"])\n",
    "        if tuple(tp[0]) in possible_tuples:\n",
    "            possible_predicted_tuples.append([tp[0], tp[1]])\n",
    "    \n",
    "    if len(possible_predicted_tuples) ==0:\n",
    "        print(\"No possible tuples for\", i)\n",
    "        print(predicted_tuples)\n",
    "        predictions_3.append(sorted(predicted_tuples, key=lambda x: x[1])[-1][0])\n",
    "    else:\n",
    "        predictions_3.append(sorted(possible_predicted_tuples, key=lambda x: x[1])[-1][0])\n",
    "predictions_3 = np.array(predictions_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86        10\n",
      "           1       1.00      0.89      0.94        18\n",
      "           5       0.82      0.82      0.82        11\n",
      "           7       0.92      0.92      0.92        26\n",
      "           8       0.99      0.99      0.99       199\n",
      "          10       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.97       264\n",
      "   macro avg       0.76      0.75      0.76       264\n",
      "weighted avg       0.97      0.97      0.97       264\n",
      "\n",
      "action\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.82         7\n",
      "           1       0.00      0.00      0.00         3\n",
      "           2       0.94      0.88      0.91        17\n",
      "           3       0.00      0.00      0.00         1\n",
      "           6       1.00      0.99      0.99       236\n",
      "           9       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.97       264\n",
      "   macro avg       0.44      0.48      0.45       264\n",
      "weighted avg       0.97      0.97      0.97       264\n",
      "\n",
      "direction\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       246\n",
      "           1       0.80      0.80      0.80        10\n",
      "           2       1.00      0.57      0.73         7\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.98       264\n",
      "   macro avg       0.76      0.67      0.70       264\n",
      "weighted avg       0.98      0.98      0.98       264\n",
      "\n",
      "meters\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       264\n",
      "\n",
      "    accuracy                           1.00       264\n",
      "   macro avg       1.00      1.00      1.00       264\n",
      "weighted avg       1.00      1.00      1.00       264\n",
      "\n",
      "degshours\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       264\n",
      "\n",
      "    accuracy                           1.00       264\n",
      "   macro avg       1.00      1.00      1.00       264\n",
      "weighted avg       1.00      1.00      1.00       264\n",
      "\n",
      "object1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        28\n",
      "           1       1.00      0.97      0.99        35\n",
      "           2       1.00      0.85      0.92        27\n",
      "           3       0.89      1.00      0.94        33\n",
      "           4       0.98      1.00      0.99        50\n",
      "           5       0.98      0.98      0.98        59\n",
      "           6       1.00      0.88      0.93        32\n",
      "           8       0.00      0.00      0.00         0\n",
      "           9       0.00      0.00      0.00         0\n",
      "          14       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.96       264\n",
      "   macro avg       0.69      0.66      0.67       264\n",
      "weighted avg       0.98      0.96      0.97       264\n",
      "\n",
      "nearest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       264\n",
      "\n",
      "    accuracy                           1.00       264\n",
      "   macro avg       1.00      1.00      1.00       264\n",
      "weighted avg       1.00      1.00      1.00       264\n",
      "\n",
      "relation1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        39\n",
      "           1       0.99      0.99      0.99       147\n",
      "           2       0.97      0.97      0.97        78\n",
      "\n",
      "    accuracy                           0.98       264\n",
      "   macro avg       0.98      0.98      0.98       264\n",
      "weighted avg       0.98      0.98      0.98       264\n",
      "\n",
      "object2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        39\n",
      "           1       0.89      0.94      0.91        33\n",
      "           2       0.97      0.85      0.91        40\n",
      "           3       0.92      0.96      0.94        24\n",
      "           4       0.92      0.98      0.95        49\n",
      "           5       0.97      0.97      0.97        39\n",
      "           6       1.00      0.97      0.99        40\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.95      0.95      0.95       264\n",
      "weighted avg       0.95      0.95      0.95       264\n",
      "\n",
      "relation2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        65\n",
      "           1       0.99      0.99      0.99       150\n",
      "           2       0.98      0.98      0.98        49\n",
      "\n",
      "    accuracy                           0.98       264\n",
      "   macro avg       0.98      0.98      0.98       264\n",
      "weighted avg       0.98      0.98      0.98       264\n",
      "\n",
      "object3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        65\n",
      "           1       0.91      0.93      0.92        44\n",
      "           2       0.75      0.90      0.82        30\n",
      "           3       0.88      0.93      0.90        40\n",
      "           4       0.58      0.54      0.56        13\n",
      "           5       0.96      0.86      0.91        50\n",
      "           6       0.95      0.82      0.88        22\n",
      "\n",
      "    accuracy                           0.90       264\n",
      "   macro avg       0.86      0.85      0.85       264\n",
      "weighted avg       0.90      0.90      0.90       264\n",
      "\n",
      "self\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       264\n",
      "           4       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           1.00       264\n",
      "   macro avg       0.50      0.50      0.50       264\n",
      "weighted avg       1.00      1.00      1.00       264\n",
      "\n",
      "gaze\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       264\n",
      "\n",
      "    accuracy                           1.00       264\n",
      "   macro avg       1.00      1.00      1.00       264\n",
      "weighted avg       1.00      1.00      1.00       264\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.0 \t correct_samples_perc\n",
      "97.0 \t [y]_acc\n",
      "76.0 \t [y]_macrof1\n",
      "97.0 \t [action]_acc\n",
      "45.0 \t [action]_macrof1\n",
      "98.0 \t [direction]_acc\n",
      "70.0 \t [direction]_macrof1\n",
      "100.0 \t [meters]_acc\n",
      "100.0 \t [meters]_macrof1\n",
      "100.0 \t [degshours]_acc\n",
      "100.0 \t [degshours]_macrof1\n",
      "96.0 \t [object1]_acc\n",
      "67.0 \t [object1]_macrof1\n",
      "100.0 \t [nearest]_acc\n",
      "100.0 \t [nearest]_macrof1\n",
      "98.0 \t [relation1]_acc\n",
      "98.0 \t [relation1]_macrof1\n",
      "95.0 \t [object2]_acc\n",
      "95.0 \t [object2]_macrof1\n",
      "98.0 \t [relation2]_acc\n",
      "98.0 \t [relation2]_macrof1\n",
      "90.0 \t [object3]_acc\n",
      "85.0 \t [object3]_macrof1\n",
      "100.0 \t [self]_acc\n",
      "50.0 \t [self]_macrof1\n",
      "100.0 \t [gaze]_acc\n",
      "100.0 \t [gaze]_macrof1\n",
      "83.0 \t avg_macro_f1\n",
      "98.0 \t avg_acc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(os.path.join(CONFIG[\"output_dir\"], \"reports\")):\n",
    "    os.mkdir(os.path.join(CONFIG[\"output_dir\"], \"reports\"))\n",
    "result = utils.calculate_metrics_2(test_y_df, predictions_3, display=True)\n",
    "with open(os.path.join(CONFIG[\"output_dir\"], \"reports/epoch-10_classes_report_rule.json\"), \"w\") as f:\n",
    "    json.dump(result, f)\n",
    "\n",
    "result_avg = utils.calculate_metrics(test_y_df, predictions_3, config={\n",
    "    \"report_metrics\": CONFIG[\"Report\"][\"report_metrics\"]\n",
    "})\n",
    "with open(os.path.join(CONFIG[\"output_dir\"], \"reports/epoch-10_avg_report_rule.json\"), \"w\") as f:\n",
    "    json.dump(result_avg, f)\n",
    "for k, v in result_avg.items():\n",
    "    print(np.round(v*100), \"\\t\", k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранить ошибки\n",
    "with open(\"../Data/Interim/labels_names.json\", \"r\") as f:\n",
    "    labels_names = json.load(f)\n",
    "predict_df = pd.DataFrame(predictions_2.astype(np.int))\n",
    "predict_df.columns = [c+\"_pred\" for c in test_y_df.columns]\n",
    "predict_df.index = test_y_df.index\n",
    "errors = pd.concat([test_x_df, test_y_df, predict_df], axis=1)\n",
    "for c in errors.columns:\n",
    "    if c in \"x\":\n",
    "        continue\n",
    "    if \"_pred\" in c:\n",
    "        errors[c] = errors[c].map(lambda x: labels_names[c.replace(\"_pred\", \"\")][x])\n",
    "    else:\n",
    "        errors[c] = errors[c].map(lambda x: labels_names[c][x])\n",
    "errors = errors.loc[:, [\"x\"] + [x for c in test_y_df.columns if c!= \"x\" for x in [c,c+\"_pred\"]]]\n",
    "\n",
    "fullDF = pd.read_csv(CONFIG[\"Data\"][\"path_to_df\"])\n",
    "fullDF = fullDF[fullDF[\"subset\"]==\"test\"]\n",
    "errors = pd.concat([errors, fullDF.loc[fullDF.index.isin(errors.index),[\"type\", \"fold\"]]], axis=1)\n",
    "\n",
    "errors.to_csv(\"../Docs/rubert_tiny2_errors_fold4_test.csv\", sep=\";\", encoding=\"cp1251\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simptr",
   "language": "python",
   "name": "simptr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
