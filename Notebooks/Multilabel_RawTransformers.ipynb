{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/s/ls4/users/grartem/RL_robots/CommandClassifier/\")\n",
    "from datasets import Dataset as HFDataset\n",
    "from RobotCommandClassifier import utils\n",
    "import pyhocon\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from RobotCommandClassifier.MyMultilabel import MyMultiLabelClassificationModel, MyMultiLabelClassificationArgs\n",
    "configFileContent = pyhocon.ConfigFactory.parse_file(\"../Configs/CustomML.conf\")\n",
    "CONFIG = configFileContent[\"MyMultiTiny2_short\"].as_plain_ordered_dict()\n",
    "train_x_df, train_y_df, valid_x_df, valid_y_df, test_x_df, test_y_df = utils.load_data(**CONFIG[\"Data\"])\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(train_y_df.values)\n",
    "\n",
    "labels = []\n",
    "encoded_labels = enc.transform(train_y_df.values).toarray().astype(int)\n",
    "for i in range(train_y_df.shape[0]):\n",
    "    labels.append(encoded_labels[i].tolist())\n",
    "train_df = pd.DataFrame(list(zip(train_x_df, labels)))\n",
    "train_df.columns = [\"text\", \"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /s/ls4/users/grartem/HuggingFace/models/rubert-tiny2 were not used when initializing MyBertForMultiLabelSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing MyBertForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MyBertForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of MyBertForMultiLabelSequenceClassification were not initialized from the model checkpoint at /s/ls4/users/grartem/HuggingFace/models/rubert-tiny2 and are newly initialized: ['myattentionoutput.seqvec_to_query_linear.weight', 'myattentionoutput.output_classifier.bias', 'myattentionoutput.seqvec_to_query_linear.bias', 'myattentionoutput.output_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "CONFIG[\"Model\"][\"Args\"][\"output_dir\"] = CONFIG[\"output_dir\"]+\"/models/\"\n",
    "CONFIG[\"Model\"][\"Args\"][\"best_model_dir\"] = CONFIG[\"output_dir\"] + \"/models/best_model\"\n",
    "model_args = MyMultiLabelClassificationArgs(**CONFIG[\"Model\"][\"Args\"])\n",
    "# Create a MultiLabelClassificationModel\n",
    "model = MyMultiLabelClassificationModel(\n",
    "    CONFIG[\"Model\"][\"model_type\"],\n",
    "    CONFIG[\"Model\"][\"model_name\"],\n",
    "    num_labels=len(labels[0]),\n",
    "    use_cuda=True,\n",
    "    num_sublabels_per_biglabel = CONFIG[\"Model\"][\"num_sublabels_per_biglabel\"],\n",
    "    add_attention_for_labels=True,\n",
    "    args=model_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MyAttentionOutput' object has no attribute 'grad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmyattentionoutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m()\n",
      "File \u001b[0;32m~/anaconda3/envs/simptr/lib/python3.8/site-packages/torch/nn/modules/module.py:1177\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1176\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1177\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1178\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MyAttentionOutput' object has no attribute 'grad'"
     ]
    }
   ],
   "source": [
    "model.model.myattentionoutput."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "9\n",
      "13\n",
      "25\n",
      "15\n",
      "2\n",
      "6\n",
      "15\n",
      "6\n",
      "15\n",
      "5\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Data/Interim/merged_with_labels_11_patterns_split.csv\")\n",
    "for c in [\"action\", \"direction\", \"meters\", \"degshours\", \"object1\", \"nearest\", \"relation1\", \"object2\", \"relation2\", \"object3\", \"self\", \"gaze\"]:\n",
    "    print(len(df[c].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f3fde16367b4a5ba6e3c92b45b57fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1502 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/s/ls4/users/grartem/anaconda3/envs/simptr/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f58be04776c3460e9c070935c600238b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35ef2252127642d5aac34e5ed07889be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 1:   0%|          | 0/188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([8, 118]) torch.Size([8, 11, 25])\n",
      "cuda:0 cuda:0\n",
      "torch.Size([6, 118]) torch.Size([6, 11, 25])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(188, 1.5783909032953547)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.train_model(train_df, overwrite_output_dir=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyMultiLabelClassificationArgs(adafactor_beta1=None, adafactor_clip_threshold=1.0, adafactor_decay_rate=-0.8, adafactor_eps=(1e-30, 0.001), adafactor_relative_step=True, adafactor_scale_parameter=True, adafactor_warmup_init=True, adam_epsilon=1e-08, best_model_dir='/s/ls4/users/grartem/RL_robots/CommandClassifier/models/MyMultiTiny2_short/models/best_model', cache_dir='cache_dir/', config={}, cosine_schedule_num_cycles=0.5, custom_layer_parameters=[], custom_parameter_groups=[], dataloader_num_workers=0, do_lower_case=False, dynamic_quantize=False, early_stopping_consider_epochs=False, early_stopping_delta=0, early_stopping_metric='eval_loss', early_stopping_metric_minimize=True, early_stopping_patience=3, encoding=None, eval_batch_size=8, evaluate_during_training=False, evaluate_during_training_silent=True, evaluate_during_training_steps=2000, evaluate_during_training_verbose=False, evaluate_each_epoch=True, fp16=True, gradient_accumulation_steps=1, learning_rate=4e-05, local_rank=-1, logging_steps=50, loss_type=None, loss_args={}, manual_seed=None, max_grad_norm=1.0, max_seq_length=128, model_name='/s/ls4/users/grartem/HuggingFace/models/rubert-tiny2', model_type='bert', multiprocessing_chunksize=-1, n_gpu=1, no_cache=False, no_save=False, not_saved_args=[], num_train_epochs=1, optimizer='AdamW', output_dir='/s/ls4/users/grartem/RL_robots/CommandClassifier/models/MyMultiTiny2_short/models/', overwrite_output_dir=False, polynomial_decay_schedule_lr_end=1e-07, polynomial_decay_schedule_power=1.0, process_count=14, quantized_model=False, reprocess_input_data=True, save_best_model=True, save_eval_checkpoints=True, save_model_every_epoch=True, save_optimizer_and_scheduler=True, save_steps=2000, scheduler='linear_schedule_with_warmup', silent=False, skip_special_tokens=True, tensorboard_dir=None, thread_count=None, tokenizer_name=None, tokenizer_type=None, train_batch_size=8, train_custom_parameters_only=False, use_cached_eval_features=False, use_early_stopping=False, use_hf_datasets=False, use_multiprocessing=True, use_multiprocessing_for_evaluation=True, wandb_kwargs={}, wandb_project=None, warmup_ratio=0.06, warmup_steps=12, weight_decay=0.0, model_class='MyMultiLabelClassificationModel', sliding_window=False, stride=0.8, threshold=0.5, tie_value=1, labels_list=[], labels_map={}, lazy_loading=False, special_tokens_list=[])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([83828, 312])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.bert.state_dict()['embeddings.word_embeddings.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/s/ls4/users/grartem/RL_robots/CommandClassifier/models/MyMultiTiny2_short'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG[\"output_dir\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simptr",
   "language": "python",
   "name": "simptr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
